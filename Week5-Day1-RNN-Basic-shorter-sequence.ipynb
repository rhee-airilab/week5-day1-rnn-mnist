{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Basic - 학습용 sequence length 의 영향"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 mini-batch 구성의 차이 FCN, 2D-CNN vs RNN\n",
    "\n",
    "- FCN ( Fully Connected Network, a.k.a. `dense` )\n",
    "\n",
    "  - `[batch, inputs]`\n",
    "  - e.g.: [`tf.layers.dense()`](http://devdocs.io/tensorflow~python/tf/layers/dense)\n",
    "\n",
    "\n",
    "- 2D-CNN 의 경우 학습데이터 feed 구성\n",
    "\n",
    "  - `[batch, height, width, channel]` : `data_format = \"NHWC\"` (default)\n",
    "  - `[batch, channel, height, width]` : `data_format = \"NCHW\"`\n",
    "  - e.g.: [`tf.layers.conv2d()`](http://devdocs.io/tensorflow~python/tf/layers/conv2d)\n",
    "\n",
    "\n",
    "\n",
    "- RNN 의 경우 학습 데이터 feed 구성\n",
    "\n",
    "  - `[batch, sequence, input]` : `time_major = False` (default for [`tf.nn.dynamic_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/dynamic_rnn))\n",
    "  - `[sequence, batch, input]` : `time_major = True`  (default for [`tf.nn.static_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/static_rnn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@media print {\n",
       "  a[href]:after {\n",
       "    content: none !important;\n",
       "  }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext do_not_print_href\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !rm -fr logdir\n",
    "# !mkdir -p logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "- 1주차 실습에 사용한 것과 동일한 데이터\n",
    "- 5주차 실습에서는 tensorflow example 의 기본 제공 메소드를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data \\\n",
    "    import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fa365222e50>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fa317389d90>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fa317389910>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = read_data_sets('./mnist', one_hot=False)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 하나만 골라서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3170ac890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "img = mnist.test.images[i,:].reshape([28,28])\n",
    "lbl = mnist.test.labels[i]\n",
    "plt.matshow(img,cmap=plt.get_cmap('gray'))\n",
    "plt.title('train[{:d}]: label={:d}'.format(i,lbl))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 학습 입력으로 사용하기 위해서 입력값의 해석 방식을 달리함\n",
    "\n",
    "- 28 x 28 = 784 개 입력값을\n",
    "\n",
    "- 28개 입력값의 길이 <span style=\"color:red\">s ( s <= 28 )</span> 인 시퀀스로 해석\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고: sequence length 제한 이전의 RNN 구조\n",
    "\n",
    "<img  src=\"Selection_20170912_110940_c175.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터의 규격 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_UNITS = 28\n",
    "NUM_HIDDEN_UNITS = 31\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 19  # <<=== s <= 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    def __init__(self, \n",
    "                 inputs, \n",
    "                 labels, \n",
    "                 input_units, \n",
    "                 num_hidden_units, \n",
    "                 batch_size, \n",
    "                 max_seq_len):\n",
    "        '''\n",
    "        inputs: in shape [batch_size, max_seq_len, input_size]\n",
    "        labels: in shape [batch_size]\n",
    "        '''\n",
    "\n",
    "        # ===>>> MultiRNNCell <<<===\n",
    "        multi_cells     = tf.contrib.rnn.MultiRNNCell([\n",
    "                            tf.contrib.rnn.BasicRNNCell(\n",
    "                                num_hidden_units) \\\n",
    "                            for _ in \\\n",
    "                            range(3) ])\n",
    "\n",
    "        sequence_length = [max_seq_len] * batch_size\n",
    "        last, states    = tf.nn.dynamic_rnn(\n",
    "                            multi_cells, \n",
    "                            inputs, \n",
    "                            sequence_length=sequence_length, \n",
    "                            dtype=tf.float32)\n",
    "        \n",
    "        # 여기서,\n",
    "        # last.shape: [batch_size, max_seq_len, num_hidden_units]\n",
    "        \n",
    "        #####################################################\n",
    "        # MultiRNNCell 을 쓰면 states값이 tensor 의 tuple 이 됨.\n",
    "        # states.shape : ([?, num_hidden_units],...)\n",
    "        #####################################################\n",
    "\n",
    "        print('last.shape', last.get_shape().as_list())\n",
    "        print('states', states)\n",
    "\n",
    "        # max_seq_len 축으로 0~27 까지 값 중에 \n",
    "        # 0~26 때의 출력 값은 사용하지 않음\n",
    "        rnn_output = last[:,max_seq_len-1,:] \n",
    "        # rnn_output shape: [batch_size, num_hidden_units]\n",
    "        print('rnn_output.shape', rnn_output.get_shape().as_list())\n",
    "\n",
    "        # 10 개의 output units 로 만들 \n",
    "        # FCN (fully-connected-network) 구성\n",
    "        # ==> shape: [batch_size, 10]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        print('outputs.shape', outputs.get_shape().as_list())\n",
    "\n",
    "        # loss 함수\n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels, outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "                        minimize(loss)\n",
    "\n",
    "        # accuracy\n",
    "        preds    = tf.argmax(outputs, axis=1)\n",
    "        errors   = tf.count_nonzero(labels - preds)\n",
    "        accuracy = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                         tf.cast(tf.size(preds),tf.float32)\n",
    "\n",
    "        # 클래스 객체 외부에서 참고할 수 있도록 속성으로 저장\n",
    "        self.outputs        = outputs\n",
    "        self.loss           = loss\n",
    "        self.optimize       = optimize\n",
    "        self.accuracy       = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.shape [128, 19, 31]\n",
      "states (<tf.Tensor 'rnn/while/Exit_2:0' shape=(128, 31) dtype=float32>, <tf.Tensor 'rnn/while/Exit_3:0' shape=(128, 31) dtype=float32>, <tf.Tensor 'rnn/while/Exit_4:0' shape=(128, 31) dtype=float32>)\n",
      "rnn_output.shape [128, 31]\n",
      "outputs.shape [128, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder(\n",
    "            tf.float32,\n",
    "            [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS],\n",
    "            name='inputs')\n",
    "labels_ = tf.placeholder(\n",
    "            tf.int64,\n",
    "            [BATCH_SIZE],\n",
    "            name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습을 위한 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 진도 기록용 summary writer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter(\n",
    "    'logdir/train3',\n",
    "    graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter(\n",
    "    'logdir/test3',\n",
    "    graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련용 데이터 시퀀스 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAX_SEQ_LEN == 28 일때\n",
    "\n",
    "\n",
    "```\n",
    "        offs        = i * BATCH_SIZE\n",
    "        batch_input = \\\n",
    "            mnist.train.images[offs:offs+BATCH_SIZE,:]\n",
    "        batch_input = \\\n",
    "            batch_input.reshape([BATCH_SIZE,\n",
    "                                    MAX_SEQ_LEN,\n",
    "                                    INPUT_UNITS])\n",
    "        batch_label = \\\n",
    "            mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAX_SEQ_LEN != 28 일때\n",
    "\n",
    "\n",
    "<code>\n",
    "        offs        = np.random.randint(\n",
    "            mnist.train.num_examples // BATCH_SIZE) *\n",
    "            BATCH_SIZE\n",
    "        batch_input = \\\n",
    "            mnist.train.images[offs:offs+BATCH_SIZE,:]\n",
    "        batch_input = \\\n",
    "            batch_input.reshape([BATCH_SIZE,\n",
    "                                    28, # MAX_SEQ_LEN,\n",
    "                                    INPUT_UNITS])\n",
    "        batch_collection = []\n",
    "        for ii in xrange(BATCH_SIZE):\n",
    "            seq_start = np.random.randint(28 - MAX_SEQ_LEN + 1)\n",
    "            batch_collection.append(\n",
    "                batch_input[\n",
    "                    ii,\n",
    "                    seq_start:seq_start+MAX_SEQ_LEN,\n",
    "                    :])\n",
    "        batch_input = np.array(batch_collection)\n",
    "        batch_label = \\\n",
    "            mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 카운트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4296, 781)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop_count = mnist.train.num_examples * \\\n",
    "        (28 - MAX_SEQ_LEN + 1) // \\\n",
    "        BATCH_SIZE\n",
    "test_loop_count  = mnist.test.num_examples * \\\n",
    "        (28 - MAX_SEQ_LEN + 1) // \\\n",
    "        BATCH_SIZE\n",
    "\n",
    "train_loop_count, test_loop_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    inputs,\n",
    "    labels,\n",
    "    max_epochs,\n",
    "    train_writer=None,\n",
    "    test_writer=None):\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(max_epochs):\n",
    "\n",
    "        train_elapsed = []\n",
    "        train_losses = []\n",
    "        train_accuracy = []\n",
    "        for i in range(train_loop_count):\n",
    "            t_start     = time.time()\n",
    "\n",
    "            offs        = np.random.randint(\n",
    "                mnist.train.num_examples // BATCH_SIZE) * \\\n",
    "                BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.train.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                        28, # MAX_SEQ_LEN,\n",
    "                                        INPUT_UNITS])\n",
    "            batch_collection = []\n",
    "            for ii in xrange(BATCH_SIZE):\n",
    "                seq_start = np.random.randint(28 - MAX_SEQ_LEN + 1)\n",
    "                batch_collection.append(\n",
    "                    batch_input[\n",
    "                        ii,\n",
    "                        seq_start:seq_start+MAX_SEQ_LEN,\n",
    "                        :])\n",
    "            batch_input = np.array(batch_collection)\n",
    "            batch_label = \\\n",
    "                mnist.train.labels[offs:offs+BATCH_SIZE]            \n",
    "            \n",
    "            optimize, loss, accuracy, = \\\n",
    "                sess.run([model.optimize,\n",
    "                          model.loss,\n",
    "                          model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            train_losses.append(loss)\n",
    "            train_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            train_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if train_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='train_accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                        tf.Summary.Value(\n",
    "                            tag='loss',\n",
    "                            simple_value=loss\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                train_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                print(('[trn] ep {:d}, step {:d}, ' + \n",
    "                       'loss {:f}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.mean(train_losses),\n",
    "                    np.amin(train_accuracy),\n",
    "                    np.mean(train_elapsed)))\n",
    "                train_losses = []\n",
    "                train_accuracy = []\n",
    "                train_elapsed = []\n",
    "\n",
    "        test_elapsed  = []\n",
    "        test_accuracy = []\n",
    "        for i in range(test_loop_count):\n",
    "            t_start     = time.time()\n",
    "\n",
    "            offs        = np.random.randint(\n",
    "                mnist.test.num_examples // BATCH_SIZE) * \\\n",
    "                BATCH_SIZE\n",
    "\n",
    "            batch_input = \\\n",
    "                mnist.test.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                        28, # MAX_SEQ_LEN,\n",
    "                                        INPUT_UNITS])\n",
    "            batch_collection = []\n",
    "            for ii in xrange(BATCH_SIZE):\n",
    "                seq_start = np.random.randint(28 - MAX_SEQ_LEN + 1)\n",
    "                batch_collection.append(\n",
    "                    batch_input[\n",
    "                        ii,\n",
    "                        seq_start:seq_start+MAX_SEQ_LEN,\n",
    "                        :])\n",
    "            batch_input = np.array(batch_collection)\n",
    "            batch_label = \\\n",
    "                mnist.test.labels[offs:offs+BATCH_SIZE]            \n",
    "\n",
    "            accuracy, = \\\n",
    "                sess.run([model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            test_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            test_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            if test_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='test_accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                test_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                print(('[tst] ep {:d}, ' +\n",
    "                       'step {:d}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.amin(test_accuracy),\n",
    "                    np.mean(test_elapsed)))\n",
    "                test_accuracy = []\n",
    "                test_elapsed  = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 500, loss 1.409534, accu 0.093750, sec/iter 0.009095\n",
      "[trn] ep 1, step 1000, loss 0.842891, accu 0.554688, sec/iter 0.008731\n",
      "[trn] ep 1, step 1500, loss 0.611520, accu 0.656250, sec/iter 0.008772\n",
      "[trn] ep 1, step 2000, loss 0.489022, accu 0.695312, sec/iter 0.008870\n",
      "[trn] ep 1, step 2500, loss 0.407674, accu 0.757812, sec/iter 0.008725\n",
      "[trn] ep 1, step 3000, loss 0.361474, accu 0.781250, sec/iter 0.009582\n",
      "[trn] ep 1, step 3500, loss 0.333060, accu 0.765625, sec/iter 0.009126\n",
      "[trn] ep 1, step 4000, loss 0.300694, accu 0.789062, sec/iter 0.008858\n",
      "[tst] ep 1, step 4500, accu 0.789062, sec/iter 0.003388\n",
      "[tst] ep 1, step 5000, accu 0.789062, sec/iter 0.003339\n",
      "[trn] ep 2, step 5500, loss 0.279479, accu 0.796875, sec/iter 0.008812\n",
      "[trn] ep 2, step 6000, loss 0.262950, accu 0.820312, sec/iter 0.008824\n",
      "[trn] ep 2, step 6500, loss 0.257611, accu 0.828125, sec/iter 0.009544\n",
      "[trn] ep 2, step 7000, loss 0.249612, accu 0.828125, sec/iter 0.009519\n",
      "[trn] ep 2, step 7500, loss 0.239785, accu 0.828125, sec/iter 0.008875\n",
      "[trn] ep 2, step 8000, loss 0.220055, accu 0.851562, sec/iter 0.008829\n",
      "[trn] ep 2, step 8500, loss 0.219775, accu 0.820312, sec/iter 0.008912\n",
      "[trn] ep 2, step 9000, loss 0.207872, accu 0.828125, sec/iter 0.008850\n",
      "[tst] ep 2, step 9500, accu 0.859375, sec/iter 0.003214\n",
      "[tst] ep 2, step 10000, accu 0.843750, sec/iter 0.003307\n"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph().finalize()\n",
    "train(inputs_, labels_, 2, train_writer, test_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 진행 점검 - 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard --ip 0.0.0.0 --logdir logdir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
