{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 기초 예제 - MNIST 문제 해결 구현\n",
    "\n",
    "1. RNN 모형\n",
    "1. RNN 학습 데이터로 사용하기 위한 mini-batch 구성\n",
    "1. 텐서플로우 RNN\n",
    "1. mnist 데이터 준비\n",
    "1. 1-layer RNN 학습 테스트\n",
    "1. stacked rnn in tensorflow\n",
    "1. 3-layer RNN 학습 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://192.168.0.29/rhee/week5-day1-rnn-mnist.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모형\n",
    "\n",
    "<img  src=\"rnn.jpg\" style=\"width:55.5rem\"/>\n",
    "\n",
    "<center>이미지 출처: http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</center>\n",
    "\n",
    "\\begin{align}\n",
    "s_t & = tanh(Ux_t + Ws_{t-1}) \\\\\n",
    "o_t & = softmax(Vs_t) \\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 mini-batch 구성의 차이 FCN, 2D-CNN vs RNN\n",
    "\n",
    "- FCN ( Fully Connected Network, a.k.a. `dense` )\n",
    "\n",
    "  - `[batch, inputs]`\n",
    "  - e.g.: [`tf.layers.dense()`](http://devdocs.io/tensorflow~python/tf/layers/dense)\n",
    "\n",
    "\n",
    "- 2D-CNN 의 경우 학습데이터 feed 구성\n",
    "\n",
    "  - `[batch, height, width, channel]` : `data_format = \"NHWC\"` (default)\n",
    "  - `[batch, channel, height, width]` : `data_format = \"NCHW\"`\n",
    "  - e.g.: [`tf.layers.conv2d()`](http://devdocs.io/tensorflow~python/tf/layers/conv2d)\n",
    "\n",
    "\n",
    "\n",
    "- RNN 의 경우 학습 데이터 feed 구성\n",
    "\n",
    "  - `[batch, sequence, input]` : `time_major = False` (default for [`tf.nn.dynamic_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/dynamic_rnn))\n",
    "  - `[sequence, batch, input]` : `time_major = True`  (default for [`tf.nn.static_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/static_rnn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모형과 tensorflow RNNCell\n",
    "\n",
    "\n",
    "<img  src=\"Selection_20170914_161757_e791.png\"/>\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "s_t & = tanh(Ux_t + Ws_{t-1}) \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- **_V_** 에 해당하는 구조가 없음\n",
    "\n",
    "- **_softmax()_** 도 없음\n",
    "\n",
    "- **_V_** 와 **_softmax()_** 는 필요할 때만 만들어서 붙이면 됨 ( `tf.layers.dense`, `tf.nn.softmax` )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 rnn 기본 클래스/함수\n",
    "\n",
    "- [`tf.contrib.rnn.BasicRNNCell()`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/basicrnncell)\n",
    "  - abstraction of RNN cell\n",
    "  - $s_t = tanh(Ux_t + Ws_{t-1})$\n",
    "\n",
    "\n",
    "\n",
    "- [`tf.nn.static_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/static_rnn)\n",
    "  - _time-major_ format inputs, outputs\n",
    "  - static unfolding\n",
    "\n",
    "\n",
    "- [`tf.nn.dynamic_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/dynamic_rnn)\n",
    "  - _batch-major_ format inputs, outputs (default)\n",
    "  - `time_major = True` for _time-major_ format\n",
    "  - dynamic unfolding using [`tf.while_loop()`](http://devdocs.io/tensorflow~python/tf/while_loop)\n",
    "  - more advanced options\n",
    "\n",
    "\n",
    "\n",
    "### [`tf.contrib.rnn.BasicRNNCell()`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/basicrnncell)\n",
    "\n",
    "<code>\n",
    "    `__init__`(\n",
    "        <span style=\"color:red\">num_units,</span>\n",
    "        activation=None,\n",
    "        reuse=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "<code>\n",
    "    `__call__`(\n",
    "        <span style=\"color:red\">inputs,</span>\n",
    "        <span style=\"color:red\">state,</span>\n",
    "        scope=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "### [`tf.nn.static_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/static_rnn)\n",
    "\n",
    "<code>\n",
    "    static_rnn(\n",
    "        <span style=\"color:red\">cell,</span>\n",
    "        <span style=\"color:red\">inputs,</span>\n",
    "        initial_state=None,\n",
    "        dtype=None,\n",
    "        <span style=\"color:red\">sequence_length=None,</span>\n",
    "        scope=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "> The simplest form of RNN network generated is:\n",
    "\n",
    "<code>\n",
    "    state = cell.zero_state(...)\n",
    "    outputs = []\n",
    "    for inp in inputs:\n",
    "      <span style=\"color:red\">output, state = cell(inp, state)</span>\n",
    "      outputs.append(output)\n",
    "    return (outputs, state)\n",
    "</code>\n",
    "\n",
    "> `sequence_length` 가 `None` 이 아니라면,\n",
    "> 배치에 포함된 각 example 들의 sequence length 를 기록한 리스트를 전달.\n",
    "> 해당 배치에서 sequence length 를 넘는 t 에 대해서는:\n",
    ">   - <span style=\"color:red\">output 은 zero</span>\n",
    ">   - state는 sequence length - 1 때의 state\n",
    "\n",
    "```\n",
    "(output, state)(b, t) =\n",
    "  (t >= sequence_length(b))\n",
    "    ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))\n",
    "    : cell(input(b, t), state(b, t - 1))\n",
    "``` \n",
    "    \n",
    "\n",
    "### [`tf.nn.dynamic_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/dynamic_rnn)\n",
    "\n",
    "<code>\n",
    "dynamic_rnn(\n",
    "    <span style=\"color:red\">cell,</span>\n",
    "    <span style=\"color:red\">inputs,</span>\n",
    "    <span style=\"color:red\">sequence_length=None,</span>\n",
    "    initial_state=None,\n",
    "    dtype=None,\n",
    "    parallel_iterations=None,\n",
    "    swap_memory=False,\n",
    "    time_major=False,\n",
    "    scope=None\n",
    ")\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@media print {\n",
       "  a[href]:after {\n",
       "    content: none !important;\n",
       "  }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext do_not_print_href\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr logdir\n",
    "!mkdir -p logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "- 1주차 실습에 사용한 것과 동일한 데이터\n",
    "- 5주차 실습에서는 tensorflow example 의 기본 제공 메소드를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1주차에 사용한 코드 (참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"border:1px solid black;border-radius:3px;width:65.0rem;margin:auto\">\n",
    "<code>\n",
    "    %%bash\n",
    "    test -s ./mnist/train-images-idx3-ubyte || (\n",
    "     mkdir -p ./mnist\n",
    "     cd ./mnist\n",
    "     echo \"$(pwd)\"\n",
    "     wget -q \\\n",
    "      http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz \\\n",
    "      http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz \\\n",
    "      http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \\\n",
    "      http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "     gzip -d *.gz\n",
    "    )\n",
    "\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"border:1px solid black;border-radius:3px;width:65.0rem;margin:auto\">\n",
    "<code>\n",
    "    data_dir = './mnist'\n",
    "    data_dir\n",
    "\n",
    "    images         = np.fromfile(data_dir + \n",
    "                         '/train-images-idx3-ubyte',dtype=np.uint8)\n",
    "    images         = images[16:].reshape([-1,28,28]).astype(np.float32)\n",
    "    images         = images / 127.0 - 1.0\n",
    "\n",
    "    labels         = np.fromfile(data_dir + \n",
    "                         '/train-labels-idx1-ubyte',dtype=np.uint8)\n",
    "    labels         = labels[8:].astype(np.int64)\n",
    "\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"border:1px solid black;border-radius:3px;width:65.0rem;margin:auto\">\n",
    "<code>\n",
    "    images.shape, images.dtype, labels.shape, labels.dtype\n",
    "\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5주차에 사용할 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data \\\n",
    "    import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd30412a810>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd2af30fd50>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd2af30fd90>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = read_data_sets('./mnist', one_hot=False)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, (55000, 784), (55000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples, \\\n",
    "mnist.train.images.shape, \\\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples, \\\n",
    "mnist.test.images.shape, \\\n",
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 하나만 골라서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2af037890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "img = mnist.test.images[i,:].reshape([28,28])\n",
    "lbl = mnist.test.labels[i]\n",
    "plt.matshow(img,cmap=plt.get_cmap('gray'))\n",
    "plt.title('train[{:d}]: label={:d}'.format(i,lbl))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 학습 입력으로 사용하기 위해서 입력값의 해석 방식을 달리함\n",
    "\n",
    "- 28 x 28 = 784 개 입력값을\n",
    "\n",
    "- 28개 입력값의 길이 28인 시퀀스로 해석\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터의 규격 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_UNITS = 28\n",
    "NUM_HIDDEN_UNITS = 31\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 카운트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 78)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop_count = mnist.train.num_examples // BATCH_SIZE\n",
    "test_loop_count  = mnist.test.num_examples // BATCH_SIZE\n",
    "\n",
    "train_loop_count, test_loop_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 만들고자 하는 RNN 네트워크 구조\n",
    "\n",
    "<img  src=\"Selection_20170912_110940_c175.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    def __init__(self, \n",
    "                 inputs, \n",
    "                 labels, \n",
    "                 input_units, \n",
    "                 num_hidden_units, \n",
    "                 batch_size, \n",
    "                 max_seq_len):\n",
    "        '''\n",
    "        inputs: in shape [batch_size, max_seq_len, input_size]\n",
    "        labels: in shape [batch_size]\n",
    "        '''\n",
    "        \n",
    "        # RNN 모델 구성\n",
    "        cell            = tf.contrib.rnn.BasicRNNCell(\n",
    "                            num_hidden_units)\n",
    "        sequence_length = [max_seq_len] * batch_size\n",
    "        last, states    = tf.nn.dynamic_rnn(\n",
    "                            cell, \n",
    "                            inputs, \n",
    "                            sequence_length=sequence_length, \n",
    "                            dtype=tf.float32)\n",
    "\n",
    "        ######################################################\n",
    "        # last.shape   : \n",
    "        #  [batch_size, max_seq_len, num_hidden_units]\n",
    "        # states.shape : \n",
    "        #  [?, num_hidden_units]\n",
    "        ######################################################\n",
    "        print('last.shape', last.get_shape().as_list())\n",
    "        print('states', states)\n",
    "\n",
    "\n",
    "        \n",
    "        ######################################################\n",
    "        # max_seq_len 축으로 0~27 까지 값 중에 0~26 출력 값은 사용하지\n",
    "        #  않음 - 모든 RNN이 그런건 아니고 경우에 따라 다름\n",
    "        # last.shape      : \n",
    "        #  [batch_size, max_seq_len, num_hidden_units]\n",
    "        # rnn_output shape: \n",
    "        #  [batch_size, num_hidden_units]\n",
    "        ######################################################\n",
    "        rnn_output = last[:,max_seq_len-1,:]\n",
    "        print('rnn_output.shape', rnn_output.get_shape().as_list())\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 10 개의 output units 로 만들 \n",
    "        #  FCN (fully-connected-network) 구성\n",
    "        # outputs shape will become: [batch_size, 10]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        print('outputs.shape', outputs.get_shape().as_list())\n",
    "\n",
    "        \n",
    "        ######################################################\n",
    "        # loss 함수: sparse_softmax_cross_entropy\n",
    "        #   label 데이터의 one-hot encoding 과,\n",
    "        #   output 데이터의 softmax() 적용이,\n",
    "        #   sparse_softmax_cross_entropy() 함수 하나에 다 들어 있음\n",
    "        ######################################################\n",
    "\n",
    "\n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels, outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "                        minimize(loss)\n",
    "\n",
    "        \n",
    "        # accuracy\n",
    "        preds    = tf.argmax(outputs, axis=1)\n",
    "        errors   = tf.count_nonzero(labels - preds)\n",
    "        accuracy = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                         tf.cast(tf.size(preds),tf.float32)\n",
    "\n",
    "        # 클래스 객체 외부에서 참고할 수 있도록 속성으로 저장\n",
    "        self.outputs        = outputs\n",
    "        self.loss           = loss\n",
    "        self.optimize       = optimize\n",
    "        self.accuracy       = accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.shape [128, 28, 31]\n",
      "states Tensor(\"rnn/while/Exit_2:0\", shape=(128, 31), dtype=float32)\n",
      "rnn_output.shape [128, 31]\n",
      "outputs.shape [128, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder(\n",
    "            tf.float32,\n",
    "            [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS],\n",
    "            name='inputs')\n",
    "labels_ = tf.placeholder(\n",
    "            tf.int64,\n",
    "            [BATCH_SIZE],\n",
    "            name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습을 위한 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 진도 기록용 summary writer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorboard logdir 지정시, 지정된 디렉토리 아래에서 이벤트 파일을 모두 찾아서 그래프로 보여줌\n",
    "\n",
    "- 따라서, 공통의 parentdir ( 예: `logdir/train` 과 `logdir/test` 의 공통 parent 인 `logdir` ) 지정시 여러 그래프를 동시에 보여 줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter(\n",
    "    'logdir/train',\n",
    "    graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter(\n",
    "    'logdir/test',\n",
    "    graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 팁: `tf.Summary()`, `tf.Summary.Value()` 를 이용하면 텐서를 만들지 않아도 summary를 기록할 수 있습니다.\n",
    "\n",
    "```\n",
    "    summary = tf.Summary(\n",
    "                value=[\n",
    "                    tf.Summary.Value(\n",
    "                        tag=tag,\n",
    "                        simple_value=value)])\n",
    "    writer.add_summary(summary, step)\n",
    "```\n",
    "\n",
    "- 하지만, histogram, audio, image 등에 적용하려면 번거로운 일이 있읍니다. 여기서는 scalar summary 만 사용\n",
    "- \"Logging to tensorboard with manually generated summaries (not relying on summary ops)\" 참고\n",
    "  - https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    inputs,\n",
    "    labels,\n",
    "    max_epochs,\n",
    "    train_writer=None,\n",
    "    test_writer=None):\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(max_epochs):\n",
    "\n",
    "        train_elapsed = []\n",
    "        train_losses = []\n",
    "        train_accuracy = []\n",
    "        for i in range(train_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.train.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                        MAX_SEQ_LEN,\n",
    "                                        INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "            optimize, loss, accuracy, = \\\n",
    "                sess.run([model.optimize,\n",
    "                          model.loss,\n",
    "                          model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            train_losses.append(loss)\n",
    "            train_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            train_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if train_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='train_accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                        tf.Summary.Value(\n",
    "                            tag='loss',\n",
    "                            simple_value=loss\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                train_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[trn] ep {:d}, step {:d}, ' + \n",
    "                       'loss {:f}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.mean(train_losses),\n",
    "                    np.amin(train_accuracy),\n",
    "                    np.mean(train_elapsed)))\n",
    "                train_losses = []\n",
    "                train_accuracy = []\n",
    "                train_elapsed = []\n",
    "\n",
    "        test_elapsed  = []\n",
    "        test_accuracy = []\n",
    "        for i in range(test_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.test.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                       MAX_SEQ_LEN,\n",
    "                                       INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.test.labels[offs:offs+BATCH_SIZE]\n",
    "            accuracy, = \\\n",
    "                sess.run([model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            test_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            test_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            if test_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='test_accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                test_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[tst] ep {:d}, ' +\n",
    "                       'step {:d}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.amin(test_accuracy),\n",
    "                    np.mean(test_elapsed)))\n",
    "                test_accuracy = []\n",
    "                test_elapsed  = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 250, loss 1.662436, accu 0.085938, sec/iter 0.007257\n",
      "[tst] ep 1, step 500, accu 0.507812, sec/iter 0.002417\n",
      "[trn] ep 2, step 750, loss 0.892362, accu 0.531250, sec/iter 0.005681\n",
      "[tst] ep 2, step 1000, accu 0.601562, sec/iter 0.002177\n",
      "[trn] ep 3, step 1250, loss 0.639886, accu 0.671875, sec/iter 0.005539\n",
      "[tst] ep 3, step 1500, accu 0.710938, sec/iter 0.002244\n",
      "[trn] ep 4, step 1750, loss 0.507841, accu 0.734375, sec/iter 0.005601\n",
      "[tst] ep 4, step 2000, accu 0.750000, sec/iter 0.002200\n",
      "[trn] ep 5, step 2250, loss 0.433358, accu 0.765625, sec/iter 0.005575\n",
      "[tst] ep 5, step 2500, accu 0.773438, sec/iter 0.002220\n",
      "[trn] ep 6, step 2750, loss 0.390744, accu 0.773438, sec/iter 0.005693\n",
      "[tst] ep 6, step 3000, accu 0.812500, sec/iter 0.002339\n",
      "[trn] ep 7, step 3250, loss 0.357466, accu 0.796875, sec/iter 0.005553\n",
      "[tst] ep 7, step 3500, accu 0.820312, sec/iter 0.002375\n",
      "[trn] ep 8, step 3750, loss 0.334627, accu 0.820312, sec/iter 0.007004\n",
      "[tst] ep 8, step 4000, accu 0.851562, sec/iter 0.002168\n",
      "[trn] ep 9, step 4250, loss 0.317587, accu 0.812500, sec/iter 0.005603\n",
      "[tst] ep 9, step 4500, accu 0.859375, sec/iter 0.002242\n",
      "[trn] ep 10, step 4750, loss 0.302175, accu 0.820312, sec/iter 0.005568\n",
      "[tst] ep 10, step 5000, accu 0.890625, sec/iter 0.002365\n"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph().finalize()\n",
    "train(inputs_, labels_, 10, train_writer, test_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 진행 점검 - 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard --ip 0.0.0.0 --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모델 구성(2) - Stacking Multiple RNN Cells\n",
    "\n",
    "- [`tf.contrib.rnn.MultiRNNCell`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/multirnncell)\n",
    "\n",
    "<code>\n",
    "    `__init__(`\n",
    "        <span style=\"color:red\">cells,</span>\n",
    "        state_is_tuple=True\n",
    "    )\n",
    "</code>\n",
    "\n",
    "> 주의: _**tensorflow**_ 1.0 이전과 1.1, 1.2 이후의 `cells` 값 지정의 의미가 달라짐\n",
    "\n",
    "  - (A) _**tensorflow**_ 1.0 이전:\n",
    "\n",
    "<code>\n",
    "    cell       = tf.contrib.rnn.BasicRNNCell(num_hidden_units)\n",
    "    multi_cell = tf.contrib.rnn.MultiRnnCell(<span style=\"color:red\">[cell] * 3</span>)\n",
    "</code>\n",
    "\n",
    "  - (B) _**tensorflow**_ 1.1:\n",
    "    - `ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.`\n",
    "    - **To fix:**\n",
    "      ```\n",
    "        multi_cell = tf.contrib.rnn.MultiRnnCell([ \\\n",
    "            tf.contrib.rnn.BasicRNNCell(num_hidden_units) \\\n",
    "            for k in range(3)])\n",
    "      ```\n",
    "\n",
    "  - _**tensorflow**_ 1.2 이후:\n",
    "    - (A)방식을 써도 `ValueError` 가 발생하지는 않지만, (A), (B) 의미가 달라짐\n",
    "    - (A)방식 : 3-layer rnn stack 을 만들지만, 각 셀의 weight 를 공유하게 된다.\n",
    "    - layer 마다 별개의 rnn cell 을 만들고 싶으면 (B) 방식으로.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    def __init__(self, \n",
    "                 inputs, \n",
    "                 labels, \n",
    "                 input_units, \n",
    "                 num_hidden_units, \n",
    "                 batch_size, \n",
    "                 max_seq_len):\n",
    "        '''\n",
    "        inputs: in shape [batch_size, max_seq_len, input_size]\n",
    "        labels: in shape [batch_size]\n",
    "        '''\n",
    "\n",
    "        # ===>>> MultiRNNCell <<<===\n",
    "        multi_cells     = tf.contrib.rnn.MultiRNNCell([\n",
    "                            tf.contrib.rnn.BasicRNNCell(\n",
    "                                num_hidden_units) \\\n",
    "                            for _ in \\\n",
    "                            range(3) ])\n",
    "\n",
    "        sequence_length = [max_seq_len] * batch_size\n",
    "        last, states    = tf.nn.dynamic_rnn(\n",
    "                            multi_cells, \n",
    "                            inputs, \n",
    "                            sequence_length=sequence_length, \n",
    "                            dtype=tf.float32)\n",
    "        \n",
    "        # 여기서,\n",
    "        # last.shape: [batch_size, max_seq_len, num_hidden_units]\n",
    "        \n",
    "        #####################################################\n",
    "        # MultiRNNCell 을 쓰면 states값이 tensor 의 tuple 이 됨.\n",
    "        # states.shape : ([?, num_hidden_units],...)\n",
    "        #####################################################\n",
    "\n",
    "        print('last.shape', last.get_shape().as_list())\n",
    "        print('states', states)\n",
    "\n",
    "        # max_seq_len 축으로 0~27 까지 값 중에 \n",
    "        # 0~26 때의 출력 값은 사용하지 않음\n",
    "        rnn_output = last[:,max_seq_len-1,:] \n",
    "        # rnn_output shape: [batch_size, num_hidden_units]\n",
    "        print('rnn_output.shape', rnn_output.get_shape().as_list())\n",
    "\n",
    "        # 10 개의 output units 로 만들 \n",
    "        # FCN (fully-connected-network) 구성\n",
    "        # ==> shape: [batch_size, 10]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        print('outputs.shape', outputs.get_shape().as_list())\n",
    "\n",
    "        # loss 함수\n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels, outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "                        minimize(loss)\n",
    "\n",
    "        # accuracy\n",
    "        preds    = tf.argmax(outputs, axis=1)\n",
    "        errors   = tf.count_nonzero(labels - preds)\n",
    "        accuracy = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                         tf.cast(tf.size(preds),tf.float32)\n",
    "\n",
    "        # 클래스 객체 외부에서 참고할 수 있도록 속성으로 저장\n",
    "        self.outputs        = outputs\n",
    "        self.loss           = loss\n",
    "        self.optimize       = optimize\n",
    "        self.accuracy       = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.shape [128, 28, 31]\n",
      "states (<tf.Tensor 'rnn/while/Exit_2:0' shape=(128, 31) dtype=float32>, <tf.Tensor 'rnn/while/Exit_3:0' shape=(128, 31) dtype=float32>, <tf.Tensor 'rnn/while/Exit_4:0' shape=(128, 31) dtype=float32>)\n",
      "rnn_output.shape [128, 31]\n",
      "outputs.shape [128, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder(\n",
    "    tf.float32,\n",
    "    [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS],\n",
    "    name='inputs')\n",
    "labels_ = tf.placeholder(\n",
    "    tf.int64,\n",
    "    [BATCH_SIZE],\n",
    "    name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter(\n",
    "    'logdir/train2',\n",
    "    graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter(\n",
    "    'logdir/test2',\n",
    "    graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 250, loss 1.210108, accu 0.117188, sec/iter 0.012381\n",
      "[tst] ep 1, step 500, accu 0.703125, sec/iter 0.004219\n",
      "[trn] ep 2, step 750, loss 0.489575, accu 0.695312, sec/iter 0.012057\n",
      "[tst] ep 2, step 1000, accu 0.773438, sec/iter 0.004077\n",
      "[trn] ep 3, step 1250, loss 0.345612, accu 0.796875, sec/iter 0.012037\n",
      "[tst] ep 3, step 1500, accu 0.828125, sec/iter 0.004014\n",
      "[trn] ep 4, step 1750, loss 0.288167, accu 0.796875, sec/iter 0.012005\n",
      "[tst] ep 4, step 2000, accu 0.851562, sec/iter 0.004372\n",
      "[trn] ep 5, step 2250, loss 0.251965, accu 0.812500, sec/iter 0.012174\n",
      "[tst] ep 5, step 2500, accu 0.867188, sec/iter 0.004039\n",
      "[trn] ep 6, step 2750, loss 0.224646, accu 0.843750, sec/iter 0.012116\n",
      "[tst] ep 6, step 3000, accu 0.875000, sec/iter 0.004018\n",
      "[trn] ep 7, step 3250, loss 0.207039, accu 0.843750, sec/iter 0.012183\n",
      "[tst] ep 7, step 3500, accu 0.875000, sec/iter 0.004154\n",
      "[trn] ep 8, step 3750, loss 0.182022, accu 0.882812, sec/iter 0.012206\n",
      "[tst] ep 8, step 4000, accu 0.890625, sec/iter 0.004082\n",
      "[trn] ep 9, step 4250, loss 0.177422, accu 0.875000, sec/iter 0.012283\n",
      "[tst] ep 9, step 4500, accu 0.890625, sec/iter 0.004715\n",
      "[trn] ep 10, step 4750, loss 0.166889, accu 0.882812, sec/iter 0.014717\n",
      "[tst] ep 10, step 5000, accu 0.914062, sec/iter 0.004244\n"
     ]
    }
   ],
   "source": [
    "train(inputs_, labels_, 10, train_writer, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !tensorboard --ip 0.0.0.0 --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "\n",
    "- Team AI Korea RNN Tutorials\n",
    "\n",
    "  - Part1 - http://aikorea.org/blog/rnn-tutorial-1/\n",
    "  - Part2 - http://aikorea.org/blog/rnn-tutorial-2/\n",
    "\n",
    "\n",
    "- WildML RNN Tutorial\n",
    "\n",
    "  - http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/\n",
    "\n",
    "\n",
    "- https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "\n",
    "- Tensorflow rnn_cell\n",
    "\n",
    "  - http://devdocs.io/tensorflow~python/tf/nn/rnn_cell\n",
    "\n",
    "\n",
    "- Tensorflow RNN Constructions\n",
    "\n",
    "  - https://www.tensorflow.org/api_guides/python/nn#Recurrent_Neural_Networks\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
